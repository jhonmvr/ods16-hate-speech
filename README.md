# üìä Resultados del Entrenamiento del Modelo de Clasificaci√≥n de Hate Speech

A continuaci√≥n se presentan las gr√°ficas obtenidas durante el entrenamiento del modelo de clasificaci√≥n, que detecta mensajes ofensivos, de odio o neutros.

---

## üéØ Precisi√≥n de Clasificaci√≥n

Esta gr√°fica muestra c√≥mo mejor√≥ la **precisi√≥n** del modelo en cada √©poca, tanto para entrenamiento como validaci√≥n:

![Train vs Val Accuracy](accuracy_plot.png)

---

## üìâ P√©rdida Total

Aqu√≠ se visualiza la **p√©rdida (loss)** en ambas fases. Una p√©rdida m√°s baja indica mejor aprendizaje:

![Train vs Val Loss](loss_plot.png)

---

## üñ•Ô∏è Uso de Recursos del Sistema

Se registraron m√©tricas del sistema para monitorear el consumo durante el entrenamiento:

### CPU

![CPU Usage](resultados/cpu_usage.png)

---

### RAM

![RAM Usage](ram_usage.png)

---

### GPU

![GPU Usage](gpu_usage.png)

---

### Memoria de GPU

![GPU Memory Usage](gpu_memory_usage.png)

---

## ‚è±Ô∏è Duraci√≥n por √âpoca

Cada √©poca del entrenamiento tom√≥ aproximadamente entre 1 y 2 segundos:

![Epoch Time](epoch_time_plot.png)

---

## ‚úÖ Conclusiones

- El modelo muestra una mejora progresiva sin signos de sobreajuste.
- El uso de recursos fue estable y eficiente.
- Puede ejecutarse en equipos con recursos moderados (CPU y GPU b√°sica).
